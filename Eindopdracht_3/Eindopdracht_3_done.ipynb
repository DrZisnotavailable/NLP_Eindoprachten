{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66594831-442a-45ba-b4d3-fa2d0d6e3fe7",
   "metadata": {
    "id": "66594831-442a-45ba-b4d3-fa2d0d6e3fe7"
   },
   "source": [
    "# Eindopdracht 3\n",
    "# Character-level LSTM met Keras — Iliad\n",
    "\n",
    "Naam: Sietse Neve\n",
    "\n",
    "Studentnummer: 1810364\n",
    "\n",
    "**Doel:** een char-level LSTM trainen op `iliad.txt` (lowercased, verder raw), met:\n",
    "- sliding window van lengte **m = 100** karakters → voorspellen **volgend** karakter\n",
    "- model: LSTM(256, return_sequences=True) → Dropout(0.2) → LSTM(256) → Dropout(0.1) → Dense(|V|, softmax)\n",
    "- optimizer **Adam**, loss **categorical_crossentropy**\n",
    "- **ModelCheckpoint** op `loss` (save_best_only)\n",
    "- na trainen: 1000 karakters genereren uit een random startsequence\n",
    "\n",
    "**Waarom char-level (i.p.v. word-level)?**\n",
    "- Geen tokenisatie/cleaning nodig; model leert spelling/patronen direct uit ruwe karakters.\n",
    "- Nadeel: langere sequenties nodig om zinsstructuur te vatten en vaak trager leren.\n",
    "\n",
    "**Wat ik ga loggen/kiezen:**\n",
    "- X vorm: `(n_sequences, 100, 1)` (1 feature = integer per timestep)\n",
    "- X normalisatie: delen door vocab_size (zodat input ≈ [0,1])\n",
    "- y: one-hot met `to_categorical`\n",
    "- 20 epochs, batch_size 128 (of minder als resources krap zijn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e605e6f-3f22-4399-b1ef-2c244e43ed35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e605e6f-3f22-4399-b1ef-2c244e43ed35",
    "outputId": "d1796735-5754-4487-e42c-c5e9f1e589a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tekstlengte (chars): 1,116,792\n",
      "Voorbeeld (eerste 200 tekens):\n",
      "the project gutenberg ebook of the iliad\n",
      "    \n",
      "this ebook is for the use of anyone anywhere in the united states and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever.\n",
      "TF versie: 2.19.0\n",
      "GPU beschikbaar: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# STAP 1: LAAD ILIAD, RAW CHAR DATA, LOWERCASE\n",
    "# ---------------------------------------------\n",
    "# Opdracht: \"Laad de data uit iliad.txt ... en converteer naar lower case.\n",
    "# Geen verdere cleaning; we gebruiken ruwe character data.\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Reproduceerbaarheid (voor zover mogelijk met GPU/cuDNN)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Pad naar databestand\n",
    "ILIAD_PATH = \"iliad.txt\"\n",
    "\n",
    "# Sliding-window lengte m (volgens opdracht = 100)\n",
    "SEQ_LEN = 100\n",
    "\n",
    "# Aantal te genereren karakters\n",
    "GEN_STEPS = 1000\n",
    "\n",
    "# Checkpoint-pad (beste loss)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "BEST_CKPT_PATH = \"checkpoints/lstm_char_best.h5\"\n",
    "\n",
    "# 1) Laad en lowercase\n",
    "with open(ILIAD_PATH, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    raw_text = f.read().lower()\n",
    "\n",
    "print(f\"Tekstlengte (chars): {len(raw_text):,}\")\n",
    "print(\"Voorbeeld (eerste 200 tekens):\")\n",
    "print(raw_text[:200])\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TF versie:\", tf.__version__)\n",
    "print(\"GPU beschikbaar:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebd6f530-a5f5-4d60-bc29-f17aeced5126",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebd6f530-a5f5-4d60-bc29-f17aeced5126",
    "outputId": "3857783e-66d3-48b3-e39f-e79ebe4cc047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 146\n",
      "Chars (eerste 100): ['\\n', ' ', '!', '#', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '§', 'à', 'ä', 'æ', 'è', 'é', 'ê', 'ë', 'ï', 'ò', 'ô', 'ö', 'ù', 'ü', 'œ', 'ά', 'έ', 'ή', 'ί', 'α', 'β', 'γ', 'δ', 'ε', 'η', 'θ', 'ι', 'κ', 'λ', 'μ', 'ν', 'ξ', 'ο', 'π', 'ρ', 'ς', 'σ', 'τ', 'υ', 'φ', 'χ', 'ω', 'ό']\n",
      "Aantal sequences (n): 1,116,692 | Sequence length (m): 100\n",
      "Voorbeeld X_int[0][:20]: [50 38 35  1 46 48 45 40 35 33 50  1 37 51 50 35 44 32 35 48] -> Y_int[0]: 39 ('i')\n"
     ]
    }
   ],
   "source": [
    "# STAP 2: UNIEKE KARAKTERS, MAPPINGS, SLIDING WINDOW\n",
    "# ---------------------------------------------------\n",
    "# - Maak lijst unieke chars en dicts: char_to_int, int_to_char\n",
    "# - Sliding window (lengte 100): X = sequences van ints, Y = 'volgend' char (als int)\n",
    "\n",
    "# Unieke karakters\n",
    "chars = sorted(list(set(raw_text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "print(\"Chars (eerste 100):\", chars[:100])\n",
    "\n",
    "# Mappings\n",
    "char_to_int = {c: i for i, c in enumerate(chars)}\n",
    "int_to_char = {i: c for c, i in char_to_int.items()}\n",
    "\n",
    "# Sliding window\n",
    "X_int = []  # elke entry is lijst met 100 ints\n",
    "Y_int = []  # target: int van het karakter na het window\n",
    "\n",
    "for i in range(0, len(raw_text) - SEQ_LEN):\n",
    "    seq_in = raw_text[i : i + SEQ_LEN]\n",
    "    seq_out = raw_text[i + SEQ_LEN]  # het eerstvolgende karakter\n",
    "    X_int.append([char_to_int[ch] for ch in seq_in])\n",
    "    Y_int.append(char_to_int[seq_out])\n",
    "\n",
    "X_int = np.array(X_int, dtype=np.int32)\n",
    "Y_int = np.array(Y_int, dtype=np.int32)\n",
    "\n",
    "print(f\"Aantal sequences (n): {X_int.shape[0]:,} | Sequence length (m): {SEQ_LEN}\")\n",
    "print(\"Voorbeeld X_int[0][:20]:\", X_int[0][:20], \"-> Y_int[0]:\", Y_int[0], f\"('{int_to_char[Y_int[0]]}')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82121338-4806-4589-bba7-670971b2ce5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82121338-4806-4589-bba7-670971b2ce5c",
    "outputId": "a75679d6-fc42-4481-943a-5a41d22a81bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dtype: int32\n",
      "X shape: (1116692, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "# STAP 3: RESHAPE NAAR 3D TENSOR (n, m, 1)\n",
    "# ----------------------------------------\n",
    "# Opdracht: \"Reshape de data in X naar (n, m, 1) ... 1 is aantal features, integer-data.\"\n",
    "# Let op: normaliseren doen we pas in stap 4.\n",
    "\n",
    "n_sequences = X_int.shape[0]        # n\n",
    "m = SEQ_LEN                         # m (100)\n",
    "X = X_int.reshape((n_sequences, m, 1))  # (n, m, 1)\n",
    "\n",
    "print(\"X dtype:\", X.dtype)\n",
    "print(\"X shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "352a916e-3d66-4010-afd2-ef436ea3885e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "352a916e-3d66-4010-afd2-ef436ea3885e",
    "outputId": "46890779-c444-4db5-8ab8-918eb1da4621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X na normalisatie — dtype: float32 min: 0.0 max: 0.9931507\n"
     ]
    }
   ],
   "source": [
    "# STAP 4: NORMALISEREN\n",
    "# --------------------\n",
    "# \"Normaliseer X door te delen door het aantal karakters in de dictionary.\"\n",
    "# Hierdoor worden integer indices geschaald naar [0,1], wat training stabiliseert.\n",
    "\n",
    "X = X.astype(np.float32) / float(vocab_size)\n",
    "print(\"X na normalisatie — dtype:\", X.dtype, \"min:\", X.min(), \"max:\", X.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27556b83-b9c5-4db7-866a-70cfdeb72df7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27556b83-b9c5-4db7-866a-70cfdeb72df7",
    "outputId": "3d58223a-da53-46d6-d13a-cee1eadf2d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: (1116692, 146) (verwacht: (n, vocab_size))\n"
     ]
    }
   ],
   "source": [
    "# STAP 5: ONE-HOT ENCODING VAN Y\n",
    "# ------------------------------\n",
    "# \"Converteer y naar een one-hot encoded representatie.\"\n",
    "# Outputdimensie = vocab_size (|V|), dus to_categorical(..., num_classes=vocab_size).\n",
    "\n",
    "y = to_categorical(Y_int, num_classes=vocab_size).astype(np.float32)\n",
    "print(\"y shape:\", y.shape, \"(verwacht: (n, vocab_size))\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20db274b-86e6-45a8-bbe4-254e7715c844",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "20db274b-86e6-45a8-bbe4-254e7715c844",
    "outputId": "174e0b20-3b9a-401e-b5f7-e3ddc409160d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">264,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">146</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,522</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m264,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m525,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m146\u001b[0m)            │        \u001b[38;5;34m37,522\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">827,026</span> (3.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m827,026\u001b[0m (3.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">827,026</span> (3.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m827,026\u001b[0m (3.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# STAP 6: MODELDEFINITIE (SEQUENTIAL)\n",
    "# -----------------------------------\n",
    "# Lagen (exact volgens opdracht):\n",
    "# 1) LSTM(256, input_shape=(m,1), return_sequences=True)\n",
    "# 2) Dropout(0.2)\n",
    "# 3) LSTM(256)\n",
    "# 4) Dropout(0.1)\n",
    "# 5) Dense(vocab_size, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(256, input_shape=(m, 1), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(256),\n",
    "    Dropout(0.1),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a147b59-4b9d-40d6-aac9-fa7c37501567",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a147b59-4b9d-40d6-aac9-fa7c37501567",
    "outputId": "ccbb91e9-a020-4068-baf7-f5148cc4be3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gecompileerd (optimizer=adam, loss=categorical_crossentropy).\n"
     ]
    }
   ],
   "source": [
    "# STAP 7: COMPILE\n",
    "# ---------------\n",
    "# \"Compile met de adam optimizer en categorical_crossentropy als loss-functie.\"\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "print(\"Model gecompileerd (optimizer=adam, loss=categorical_crossentropy).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "772e3c36-4981-483e-ac3c-faa623d2b546",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "772e3c36-4981-483e-ac3c-faa623d2b546",
    "outputId": "abd341fb-f230-4e09-d102-2d74eb10e92c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8724/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.8677\n",
      "Epoch 1: loss improved from inf to 2.67094, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 30ms/step - loss: 2.8677\n",
      "Epoch 2/20\n",
      "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.3728\n",
      "Epoch 2: loss improved from 2.67094 to 2.30957, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 30ms/step - loss: 2.3728\n",
      "Epoch 3/20\n",
      "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.1621\n",
      "Epoch 3: loss improved from 2.30957 to 2.12581, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 30ms/step - loss: 2.1620\n",
      "Epoch 4/20\n",
      "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.0420\n",
      "Epoch 4: loss improved from 2.12581 to 2.01639, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 30ms/step - loss: 2.0420\n",
      "Epoch 5/20\n",
      "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.9557\n",
      "Epoch 5: loss improved from 2.01639 to 1.93749, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 30ms/step - loss: 1.9556\n",
      "Epoch 6/20\n",
      "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.8953\n",
      "Epoch 6: loss improved from 1.93749 to 1.88127, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 30ms/step - loss: 1.8953\n",
      "Epoch 7/20\n",
      "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.8483\n",
      "Epoch 7: loss improved from 1.88127 to 1.83784, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 30ms/step - loss: 1.8483\n",
      "Epoch 8/20\n",
      "\u001b[1m8724/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.8130\n",
      "Epoch 8: loss improved from 1.83784 to 1.80390, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 30ms/step - loss: 1.8130\n",
      "Epoch 9/20\n",
      "\u001b[1m8724/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.7848\n",
      "Epoch 9: loss improved from 1.80390 to 1.77620, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 30ms/step - loss: 1.7848\n",
      "Epoch 10/20\n",
      "\u001b[1m8724/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.7603\n",
      "Epoch 10: loss improved from 1.77620 to 1.75190, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 30ms/step - loss: 1.7603\n",
      "Epoch 11/20\n",
      "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.7386\n",
      "Epoch 11: loss improved from 1.75190 to 1.73164, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 30ms/step - loss: 1.7386\n",
      "Epoch 12/20\n",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.7196\n",
      "Epoch 12: loss improved from 1.73164 to 1.71470, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 30ms/step - loss: 1.7196\n",
      "Epoch 13/20\n",
      "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.7041\n",
      "Epoch 13: loss improved from 1.71470 to 1.69885, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 30ms/step - loss: 1.7041\n",
      "Epoch 14/20\n",
      "\u001b[1m8724/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.6876\n",
      "Epoch 14: loss improved from 1.69885 to 1.68333, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 30ms/step - loss: 1.6876\n",
      "Epoch 15/20\n",
      "\u001b[1m8724/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.6762\n",
      "Epoch 15: loss improved from 1.68333 to 1.67229, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 30ms/step - loss: 1.6762\n",
      "Epoch 16/20\n",
      "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.6633\n",
      "Epoch 16: loss improved from 1.67229 to 1.65947, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 30ms/step - loss: 1.6633\n",
      "Epoch 17/20\n",
      "\u001b[1m8724/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.6518\n",
      "Epoch 17: loss improved from 1.65947 to 1.64793, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 30ms/step - loss: 1.6518\n",
      "Epoch 18/20\n",
      "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.6410\n",
      "Epoch 18: loss improved from 1.64793 to 1.63844, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 30ms/step - loss: 1.6410\n",
      "Epoch 19/20\n",
      "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.6323\n",
      "Epoch 19: loss improved from 1.63844 to 1.62886, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 30ms/step - loss: 1.6323\n",
      "Epoch 20/20\n",
      "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.6219\n",
      "Epoch 20: loss improved from 1.62886 to 1.61961, saving model to checkpoints/lstm_char_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 30ms/step - loss: 1.6219\n"
     ]
    }
   ],
   "source": [
    "# STAP 8: TRAINING + CHECKPOINT\n",
    "# -----------------------------\n",
    "# \"Fit het model ... 20 epochs, batch_size 128. Gebruik ModelCheckpoint(..., monitor='loss',\n",
    "#  save_best_only=True, mode='min').\"\n",
    "#\n",
    "# NB: Dit kan op CPU lang duren. Met GPU (Colab) gaat het per epoch sneller.\n",
    "# We monitoren 'loss' (train loss), zoals expliciet gevraagd.\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    filepath=BEST_CKPT_PATH,\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "history = model.fit(\n",
    "    X, y,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[checkpoint_cb]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dfb0231-3b7b-4f74-9080-541334d10f9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dfb0231-3b7b-4f74-9080-541334d10f9f",
    "outputId": "094951e2-98c7-4b9e-8d3e-8639cac6cfcd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste model geladen uit: checkpoints/lstm_char_best.h5\n",
      "\n",
      "=== Startsequence (100 chars) ===\n",
      "ge thy servant, and the greeks destroy.”\n",
      "\n",
      "thus chryses pray’d:—the favouring power attends,\n",
      "and from\n"
     ]
    }
   ],
   "source": [
    "# STAP 9: BESTE MODEL LADEN + RANDOM STARTSEQUENCE\n",
    "# ------------------------------------------------\n",
    "# \"Laad het model met de beste loss en compile dit. Kies een random startsequence uit X en print deze.\"\n",
    "\n",
    "best_model = load_model(BEST_CKPT_PATH)\n",
    "best_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "print(\"Beste model geladen uit:\", BEST_CKPT_PATH)\n",
    "\n",
    "# Kies een random seedsequence uit de trainingsdata (als ints, lengte 100)\n",
    "start_idx = np.random.randint(0, n_sequences)\n",
    "seed_seq = X_int[start_idx].tolist()  # let op: X_int zijn *ints* (pre-normalisatie)\n",
    "seed_text = \"\".join(int_to_char[i] for i in seed_seq)\n",
    "\n",
    "print(\"\\n=== Startsequence (100 chars) ===\")\n",
    "print(seed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a57dcedb-1981-43d8-bfa5-c82e236f1989",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a57dcedb-1981-43d8-bfa5-c82e236f1989",
    "outputId": "f53eeff3-7386-4eef-df68-8b6ec16c2c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the shades of the shores of fate.\n",
      "the shout a shout the shades of the shore,\n",
      "and the shoued shades of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a force of the shores of fate.\n",
      "the shout a forc\n",
      "\n",
      "=== Klaar met genereren ===\n"
     ]
    }
   ],
   "source": [
    "# STAP 10: GENEREREN VAN 1000 KARAKTERS\n",
    "# -------------------------------------\n",
    "# Voor elke stap:\n",
    "# - Reshape huidige sequence naar (1, m, 1) en normaliseer (/ vocab_size)\n",
    "# - Predict softmax, neem argmax → integer\n",
    "# - Converteer int → char en print zonder newline\n",
    "# - Schuif window: laatste 99 + nieuw char\n",
    "\n",
    "generated = []\n",
    "pattern = list(seed_seq)  # kopie van de startsequence (ints)\n",
    "\n",
    "for step in range(GEN_STEPS):\n",
    "    x_in = np.array(pattern, dtype=np.float32).reshape(1, m, 1) / float(vocab_size)\n",
    "    proba = best_model.predict(x_in, verbose=0)[0]  # (vocab_size,)\n",
    "    next_idx = int(np.argmax(proba))                # argmax volgens opdracht\n",
    "    next_char = int_to_char[next_idx]\n",
    "    print(next_char, end=\"\")                        # geen newline\n",
    "    generated.append(next_char)\n",
    "    pattern = pattern[1:] + [next_idx]             # schuif window 1 naar rechts\n",
    "\n",
    "print(\"\\n\\n=== Klaar met genereren ===\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "tvLLHb2KliGe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "tvLLHb2KliGe",
    "outputId": "2b191bf6-310c-4e82-d2ee-6a9f58a05fa2"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_75a477eb-1721-4227-b44b-e0915d4a20f4\", \"lstm_char_best.h5\", 9963664)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download(\"checkpoints/lstm_char_best.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M8by9Zgl9lkM",
   "metadata": {
    "id": "M8by9Zgl9lkM"
   },
   "source": [
    "## Observaties, tekortkomingen, verbeteringen\n",
    "\n",
    "ik zie dat mijn model korte patronen zoals the shout en the shades goed oppakt\n",
    "het kan dus echt leren hoe woorden gespeld moeten worden en hoe zinnen beginnen\n",
    "maar na een tijdje gaat het steeds hetzelfde stuk herhalen\n",
    "het blijft hangen in the shout a force of the shores of fate\n",
    "dat komt omdat ik bij het genereren steeds argmax gebruik\n",
    "dan kies ik altijd het meest waarschijnlijke karakter en dat maakt de tekst heel voorspelbaar\n",
    "mijn conclusie is dat de LSTM wel lokale structuur leert maar moeite heeft met lange afstand\n",
    "ik zou dit kunnen verbeteren door sampling met temperature te gebruiken of top k sampling\n",
    "dan wordt de output minder repetitief en creatiever\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
