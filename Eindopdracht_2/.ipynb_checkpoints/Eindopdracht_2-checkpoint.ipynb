{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a3da38-e297-46d4-9071-e46cd681bdaf",
   "metadata": {},
   "source": [
    "# Eindopdracht 2: Machine Translation & Document Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd10e14-1e3e-4a2b-bb6a-6b5c6ba1c8f6",
   "metadata": {},
   "source": [
    "Naam: Sietse Neve\n",
    "\n",
    "Studentnummer: 1810364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e766a-5509-49a1-8e9c-94d19ec1d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------\n",
    "# 1. Data inladen\n",
    "# -----------------------\n",
    "\n",
    "# Engelse embeddings\n",
    "with open(\"en_embeddings.p\", \"rb\") as f:\n",
    "    en_embeddings = pickle.load(f)\n",
    "\n",
    "# Franse embeddings\n",
    "with open(\"fr_embeddings.p\", \"rb\") as f:\n",
    "    fr_embeddings = pickle.load(f)\n",
    "\n",
    "# Train- en testset\n",
    "train_pairs = []\n",
    "with open(\"en-fr.train.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        en, fr = line.strip().split()\n",
    "        train_pairs.append((en, fr))\n",
    "\n",
    "test_pairs = []\n",
    "with open(\"en-fr.test.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        en, fr = line.strip().split()\n",
    "        test_pairs.append((en, fr))\n",
    "\n",
    "# -----------------------\n",
    "# 2. Lossfunctie & gradient\n",
    "# -----------------------\n",
    "\n",
    "def loss_and_gradient(W, X, Y):\n",
    "    \"\"\"\n",
    "    Bereken de loss (Frobenius norm) en de bijbehorende gradient.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    W : np.ndarray\n",
    "        Huidige transformatie matrix (dim n x n)\n",
    "    X : np.ndarray\n",
    "        Bronvectors (dim m x n)\n",
    "    Y : np.ndarray\n",
    "        Doelvectors (dim m x n)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "        Frobenius norm loss\n",
    "    gradient : np.ndarray\n",
    "        Gradient van de loss naar W\n",
    "    \"\"\"\n",
    "    diff = X @ W - Y\n",
    "    loss = np.sum(diff ** 2) / X.shape[0]\n",
    "    gradient = (2 / X.shape[0]) * X.T @ diff\n",
    "    return loss, gradient\n",
    "\n",
    "# -----------------------\n",
    "# 3. Train/test filteren en matrices bouwen\n",
    "# -----------------------\n",
    "def filter_pairs(pairs, en_emb, fr_emb):\n",
    "    kept = []\n",
    "    for en, fr in pairs:\n",
    "        if (en in en_emb) and (fr in fr_emb):\n",
    "            kept.append((en, fr))\n",
    "    return kept\n",
    "\n",
    "train_pairs_f = filter_pairs(train_pairs, en_embeddings, fr_embeddings)\n",
    "test_pairs_f  = filter_pairs(test_pairs,  en_embeddings, fr_embeddings)\n",
    "\n",
    "print(f\"Train: {len(train_pairs_f)} kept\")\n",
    "print(f\"Test : {len(test_pairs_f)} kept\")\n",
    "\n",
    "X_train = np.array([en_embeddings[en] for en, fr in train_pairs_f])  # (m, n)\n",
    "Y_train = np.array([fr_embeddings[fr] for en, fr in train_pairs_f])  # (m, n)\n",
    "\n",
    "n_dim = X_train.shape[1]\n",
    "W = np.eye(n_dim)\n",
    "\n",
    "# -----------------------\n",
    "# 4. Gradient descent (400 stappen, lr=0.8)\n",
    "# -----------------------\n",
    "learning_rate = 0.8\n",
    "steps = 400\n",
    "\n",
    "for step in range(steps):\n",
    "    loss, grad = loss_and_gradient(W, X_train, Y_train)\n",
    "    W -= learning_rate * grad\n",
    "    if step % 50 == 0 or step == steps - 1:  # ook laatste stap printen\n",
    "        print(f\"Stap {step}: loss = {loss:.4f}\")\n",
    "\n",
    "# -----------------------\n",
    "# 5. Cosine similarity (helper)\n",
    "# -----------------------\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# -----------------------\n",
    "# 6. KNN (k=1) met vectorisatie over alle Franse woorden\n",
    "# -----------------------\n",
    "# Maak een matrix met alle FR-embeddings (rijen) en bijbehorende woordenlijst\n",
    "fr_words = list(fr_embeddings.keys())\n",
    "F = np.array([fr_embeddings[w] for w in fr_words])          # (N_fr, n)\n",
    "F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)       # nodig voor cosine\n",
    "\n",
    "def translate(word, W, en_embeddings, fr_words, F_norm):\n",
    "    v = en_embeddings[word] @ W                              # (n,)\n",
    "    v = v / np.linalg.norm(v)                                # cosine: unit vector\n",
    "    sims = F_norm @ v                                        # (N_fr,)\n",
    "    idx = int(np.argmax(sims))\n",
    "    return fr_words[idx]\n",
    "\n",
    "# -----------------------\n",
    "# 7. Accuracy op gefilterde testset\n",
    "# -----------------------\n",
    "correct = 0\n",
    "incorrect = []\n",
    "for en, fr in test_pairs_f:\n",
    "    pred = translate(en, W, en_embeddings, fr_words, F_norm)\n",
    "    if pred == fr:\n",
    "        correct += 1\n",
    "\n",
    "    else:\n",
    "        incorrect.append(pred)\n",
    "\n",
    "accuracy = correct / len(test_pairs_f) if test_pairs_f else 0.0\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36270f73-752c-458c-aeb6-948bc88a3c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
